{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Major Project (45513295).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LXIQ1uspYJoz","colab_type":"text"},"source":["This notebook is for the major project submission, on the **language** dataset and task. It contains the following sections:\n","\n","*   Loading the Data\n","\n","*   Exploratory Analysis of the data\n","*   Feature Engineering on the data\n","*   Conventional Machine Learning Model\n","*   A description of the selected conventional ML Model\n","*   Deep Learning Model\n","*   A description of the selected Deep Learning Model\n","*   Discussion between the performances of the two models\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tZWdaaO0MQ03"},"source":["# ***1) Loading the Data***"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OPook2sMMSMT","outputId":"c4f9247e-77d1-479a-eafa-917ecf82253d","executionInfo":{"status":"ok","timestamp":1591347616759,"user_tz":-600,"elapsed":2891,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["import numpy as np\n","import pandas as pd\n","from os.path import join\n","from google.colab import drive\n","import pickle\n","\n","drive.mount('/content/drive/')\n","\n","def load_pickle(path):\n","    with open(path, 'rb') as f:\n","        file = pickle.load(f)\n","        print ('Loaded %s..' %path)\n","        return file\n","\n","dataset_directory = '/content/drive/My Drive/ML Project/tweet-emotion-detection' \n","\n","emotions = ['anger', 'fear', 'joy', 'sadness']\n","\n","tweets_train = np.load(join(dataset_directory, 'text_train_tweets.npy'))\n","labels_train = np.load(join(dataset_directory, 'text_train_labels.npy'))\n","vocabulary = load_pickle(join(dataset_directory, 'text_word_to_idx.pkl'))\n","\n","tweets_val = np.load(join(dataset_directory, 'text_val_tweets.npy'))\n","labels_val = np.load(join(dataset_directory, 'text_val_labels.npy'))\n","\n","tweets_test_private = np.load(join(dataset_directory, 'text_test_private_tweets.npy'))\n","\n","print(len(vocabulary))\n","idx_to_word = {i: w for w, i in vocabulary.items()}\n","for i in range(7):\n","  print(i, idx_to_word[i])\n","\n","sample = 1  \n","\n","print('sample tweet, stored form:')\n","print(tweets_train[sample])\n","print(labels_train[sample])\n","\n","print('sample tweet, readable form:')\n","\n","decode = []\n","for i in range(50):\n","  decode.append(idx_to_word[tweets_train[sample][i]])\n","print(decode)\n","print(emotions[labels_train[sample]])\n","\n","\n","print(tweets_train.shape)\n","print(labels_train.shape)\n","print(tweets_val.shape)\n","print(labels_val.shape)\n","print(tweets_test_private.shape)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","Loaded /content/drive/My Drive/ML Project/tweet-emotion-detection/text_word_to_idx.pkl..\n","13978\n","0 <NULL>\n","1 <START>\n","2 <END>\n","3 it\n","4 makes\n","5 me\n","6 so\n","sample tweet, stored form:\n","[ 1 23 24 20 25 19 26 27 28  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0]\n","0\n","sample tweet, readable form:\n","['<START>', 'lol', 'adam', 'the', 'bull', 'with', 'his', 'fake', 'outrage', '<END>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>']\n","anger\n","(7098, 52)\n","(7098,)\n","(1460, 52)\n","(1460,)\n","(4257, 52)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C3aRktHbabGr","colab_type":"text"},"source":["# ***2) Exploratory Analysis of the data***"]},{"cell_type":"code","metadata":{"id":"ijFfv-uQowPG","colab_type":"code","outputId":"6761f431-231e-4f35-bda1-e56b0e95a111","executionInfo":{"status":"ok","timestamp":1591347617596,"user_tz":-600,"elapsed":3705,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["arr = np.array(tweets_train)\n","X_train = pd.DataFrame(data=arr.flatten())\n","print(X_train)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["        0\n","0       1\n","1       3\n","2       4\n","3       5\n","4       6\n","...    ..\n","369091  0\n","369092  0\n","369093  0\n","369094  0\n","369095  0\n","\n","[369096 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QuTyY3wHr1Za","colab_type":"code","outputId":"0d76ce12-b349-4a69-85f5-ba0d75802e25","executionInfo":{"status":"ok","timestamp":1591347617614,"user_tz":-600,"elapsed":3620,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["arr1 = np.array(labels_train)\n","y_train = pd.DataFrame(data=arr1.flatten())\n","print(y_train)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["      0\n","0     0\n","1     0\n","2     0\n","3     0\n","4     0\n","...  ..\n","7093  3\n","7094  3\n","7095  3\n","7096  3\n","7097  3\n","\n","[7098 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HU4gHRGV1MMW","colab_type":"text"},"source":["# ***3) Feature Engineering on the data***\n","\n","***Converting index to words***"]},{"cell_type":"code","metadata":{"id":"hDgkPw38w-Ey","colab_type":"code","outputId":"b7a797b8-62be-475c-f5e8-80da32cc1069","executionInfo":{"status":"ok","timestamp":1591347890257,"user_tz":-600,"elapsed":276206,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["# preprocessing the X_train (training data)\n","\n","df=pd.DataFrame(tweets_train)\n","for i in range(13978):\n","  df.replace(i, idx_to_word[i], inplace=True)\n","X_train=df.values\n","X_train"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['<START>', 'it', 'makes', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', 'lol', 'adam', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', '<user>', 'passed', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ...,\n","       ['<START>', '#vinb', 'i', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', 'overwhelming', 'sadness', ..., '<NULL>', '<NULL>',\n","        '<NULL>'],\n","       ['<START>', 'idk', 'why', ..., '<NULL>', '<NULL>', '<NULL>']],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Qe8rPqtSCJ_m","colab_type":"code","outputId":"626b599b-7a5d-40e7-82ab-39460112d28c","executionInfo":{"status":"ok","timestamp":1591347890264,"user_tz":-600,"elapsed":276005,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(X_train.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(7098, 52)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7xcJEajI8itE","colab_type":"code","outputId":"253081a1-86b0-4bf3-fb20-aaa861721b12","executionInfo":{"status":"ok","timestamp":1591348031187,"user_tz":-600,"elapsed":416851,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# preprocessing the x_val (validation data)\n","\n","df2=pd.DataFrame(tweets_val)\n","for i in range(13978):\n","  df2.replace(i, idx_to_word[i], inplace=True)\n","x_val=df2.values\n","x_val"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['<START>', '<user>', '<user>', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', 'had', 'a', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', '#cnn', 'really', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ...,\n","       ['<START>', 'i', 'wont', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', 'and', 'after', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', 'hit', 'by', ..., '<NULL>', '<NULL>', '<NULL>']],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"B9LcIHiu5Q-W","colab_type":"code","outputId":"8c30f8a8-a892-44e6-bfa4-e74aff08dc62","executionInfo":{"status":"ok","timestamp":1591348031194,"user_tz":-600,"elapsed":416750,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(x_val.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(1460, 52)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i_NBm1F7IXKc","colab_type":"code","outputId":"e38f5336-56a4-4dcd-8c43-e308bff63560","executionInfo":{"status":"ok","timestamp":1591348239632,"user_tz":-600,"elapsed":625158,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# preprocessing the x_test (test data)\n","\n","df3=pd.DataFrame(tweets_test_private)\n","for i in range(13978):\n","  df3.replace(i, idx_to_word[i], inplace=True)\n","x_test=df3.values\n","x_test"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['<START>', 'whatever', 'you', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', 'accept', 'the', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', 'my', 'roommate', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ...,\n","       ['<START>', '<user>', ':', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', 'you', 'have', ..., '<NULL>', '<NULL>', '<NULL>'],\n","       ['<START>', '<user>', '<user>', ..., '<NULL>', '<NULL>', '<NULL>']],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"cdzRdYjd5XdJ","colab_type":"code","outputId":"44bbba7d-524e-40dc-f07d-0b7b90f69a5e","executionInfo":{"status":"ok","timestamp":1591348239639,"user_tz":-600,"elapsed":625134,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(x_test.shape)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(4257, 52)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F-x6RnBkz3xO","colab_type":"text"},"source":["**TF-IDF Vectors as Features**"]},{"cell_type":"code","metadata":{"id":"6mcX8kFUAexF","colab_type":"code","outputId":"52153c93-6413-47d5-f990-36ac449ef71a","executionInfo":{"status":"ok","timestamp":1591348240123,"user_tz":-600,"elapsed":625591,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Feature extraction code\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","vectorizer = TfidfVectorizer(preprocessor= lambda x: x,\n","                             tokenizer = lambda x: x,\n","                             stop_words = stopwords.words('english'),\n","                             max_features=5000,\n","                             min_df=3, max_df=0.9)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"91mmdev7GLEW","colab_type":"code","outputId":"d41e877c-1c25-4288-fa76-f063da4015d1","executionInfo":{"status":"ok","timestamp":1591348240635,"user_tz":-600,"elapsed":626043,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# Transformation code\n","\n","X_train_idf = vectorizer.fit_transform(X_train)\n","\n","X_val_idf = vectorizer.transform(x_val)\n","\n","x_test = vectorizer.transform(x_test)\n","\n","y_train = labels_train\n","y_val = labels_val"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n","  'stop_words.' % sorted(inconsistent))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gWHbk4TgzTMI","colab_type":"code","outputId":"861c396d-a11b-4b4d-d3a1-1fc1d6bfccf7","executionInfo":{"status":"ok","timestamp":1591348240638,"user_tz":-600,"elapsed":626004,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["print('x_train shape:', X_train_idf.shape)\n","print('x_val shape:', X_val_idf.shape)\n","print('y_train shape:', y_train.shape)\n","print('y_val shape:', y_val.shape)\n","print('x_test shape:', x_test.shape)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["x_train shape: (7098, 3903)\n","x_val shape: (1460, 3903)\n","y_train shape: (7098,)\n","y_val shape: (1460,)\n","x_test shape: (4257, 3903)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dfemc0EA1GHZ","colab_type":"text"},"source":["# ***4) Conventional Machine Learning Model***\n","\n","***The final model that produced the best-performing predictions for the Kaggle submission (accuracy of 52% on public test set and 63% on private test set) was an SVM with a linear kernel.***"]},{"cell_type":"code","metadata":{"id":"gYPcL_r-O1hM","colab_type":"code","colab":{}},"source":["# Conventional ML model definition code\n","\n","from sklearn import svm\n","\n","clf = svm.SVC(kernel='linear') # Linear Kernel\n","\n","#Trained the model using the training sets after feature extraction\n","\n","clf.fit(X_train_idf, y_train)\n","\n","#Predicted the response for the validation dataset\n","\n","y_pred = clf.predict(X_val_idf)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"03z5QA72QrOJ","colab_type":"code","outputId":"1045a6c0-7aa8-4c6a-9129-bfa79f8d23f9","executionInfo":{"status":"ok","timestamp":1591348245978,"user_tz":-600,"elapsed":631231,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Checked the accuracy for SVM Linear Kernel on the validation set\n","\n","from sklearn.metrics import accuracy_score\n","print(\"Conventional ML Model Accuracy Score:\", accuracy_score(y_val, y_pred))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Conventional ML Model Accuracy Score: 0.4321917808219178\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PJb7GP0dQ8fW","colab_type":"code","colab":{}},"source":["#Predicted the response for the test dataset\n","\n","predsvm = clf.predict(x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bdvh4KpYRMfA","colab_type":"code","colab":{}},"source":["#Saving file as CSV\n","\n","import numpy as np\n","import pandas as pd\n","prediction_svm = pd.DataFrame(predsvm, columns=['Prediction'])\n","prediction_svm.to_csv('/content/drive/My Drive/ML Project/tweet-emotion-detection/prediction_svm.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kmrVcjErb7wq","colab_type":"text"},"source":["# ***5) A Description of the Selected Conventional ML Model***\n","\n","The final conventional ML Model of **SVM Linear Classifier** resulted in an accuracy of 0.432 (43.2%) on the validation set. Whereas, it gave an accuracy of 0.52 (52%) on the public test set on Kaggle. This may have been because SVM is known to work better for text classification compared to other models and the data was linearly separable as well which is also why our SVM Model worked well. (implemented hyperparameter tuning of kernel type in SVM, where polynomial kernel did not work well and linear kernel worked better)\n","\n","In addition to the final model, I also tried a ***KNN Model*** and ***Random Forest Model***. These models performed fairly poorly comparatively. While, KNN Classifier resulted in an accuracy of 0.36 on the validation set and gave an accuracy of 0.30 on the public test set when using number of neighbours as 3 as other hyperparameters (n= 1, 2) performed poorly (implemented hyperparameter tuning of number of neighbours in KNN), the Random Forest Classifier resulted in an accuracy of 0.429 on the validation set. Whereas, it gave an accuracy of 0.51 on the public test set (implemented hyperparameter tuning by changing values of n_estimators using values as 100, 200 etc. in Random Forest classifer). This may have been because in the case of KNN, for large datasets like ours, the performance of the algorithm gets degraded due to higher cost of calculation and also, KNN is sensitive to outliers & noisy data. For Random Forest algorithm, the feature is required to have some predictive power or it may not work well with the data which seems to be our case and training a large amount of trees has high computational costs leading to degradation of our performance and accuracy metrics.\n","\n","Hence, I decided to choose SVM Linear Classifier as the best conventional ML Model. "]},{"cell_type":"markdown","metadata":{"id":"McSOgf6TI5OZ","colab_type":"text"},"source":["# ***6) Deep Learning Model***\n","\n","The final model that produced the best-performing predictions for the Kaggle submission (Accuracy of 54.65% on public test set and 64% on private test set) was a fully connected dense model with NN layers.  The input was the raw data that had been preprocessed by feature extraction using TF-IDF."]},{"cell_type":"code","metadata":{"id":"SkQfYZt5BU7s","colab_type":"code","outputId":"0a073dcf-0723-4d6a-b809-361054cbbfc0","executionInfo":{"status":"ok","timestamp":1591348252879,"user_tz":-600,"elapsed":637654,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["pip install keras"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E_uAFPYmPheZ","colab_type":"code","outputId":"bf91c72f-6dfe-42db-823b-6a1af3abf0ba","executionInfo":{"status":"ok","timestamp":1591348254244,"user_tz":-600,"elapsed":638933,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# pre-processing training labels and validation labels to categorical data\n","\n","import tensorflow as tf\n","import keras\n","from keras.utils import to_categorical\n","y_train = keras.utils.to_categorical(y_train)\n","y_val = keras.utils.to_categorical(y_val)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MPBAjsOcL3G-","colab_type":"code","colab":{}},"source":["# Deep Model definition code\n","\n","from keras.models import Sequential\n","from keras import layers\n","\n","input_dim = X_train_idf.shape[1]  # Number of features\n","\n","model = Sequential()\n","\n","model.add(layers.Dense(12, input_dim=(3903), activation='relu')) #Activation dense input layer using relu activation\n","\n","model.add(layers.Dropout(0.5)) #Dropout layer for regularization\n","\n","model.add(layers.Dropout(0.25)) #Dropout layer for regularization\n","\n","model.add(layers.Dense(4, activation='softmax')) #Output dense layer using softmax activation\n","\n","#Referred to Lecture Notes (Week 9) for the idea of the code"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ue5RQIgMGTu","colab_type":"code","outputId":"2504dba7-2fce-40d9-e2af-ee83a29bfa29","executionInfo":{"status":"ok","timestamp":1591348255550,"user_tz":-600,"elapsed":640189,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["#Compilation using the loss feature, optimizer and metrics of the Deep Learning Model\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 12)                46848     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12)                0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 12)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4)                 52        \n","=================================================================\n","Total params: 46,900\n","Trainable params: 46,900\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hkmfkJYRMLWI","colab_type":"code","outputId":"964933dc-97af-4f60-b745-4e4898d491b7","executionInfo":{"status":"ok","timestamp":1591348290337,"user_tz":-600,"elapsed":674895,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["#Fitted the deep learning model on validation set\n","\n","history = model.fit(X_train_idf, y_train, epochs=10, verbose=1, \n","                    validation_data=(X_val_idf, y_val),batch_size=10)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Train on 7098 samples, validate on 1460 samples\n","Epoch 1/10\n","7098/7098 [==============================] - 4s 535us/step - loss: 1.3324 - accuracy: 0.3660 - val_loss: 1.3483 - val_accuracy: 0.3493\n","Epoch 2/10\n","7098/7098 [==============================] - 3s 481us/step - loss: 1.1226 - accuracy: 0.5428 - val_loss: 1.2987 - val_accuracy: 0.4110\n","Epoch 3/10\n","7098/7098 [==============================] - 3s 484us/step - loss: 0.9148 - accuracy: 0.6307 - val_loss: 1.2892 - val_accuracy: 0.4425\n","Epoch 4/10\n","7098/7098 [==============================] - 3s 486us/step - loss: 0.7623 - accuracy: 0.6855 - val_loss: 1.3243 - val_accuracy: 0.4473\n","Epoch 5/10\n","7098/7098 [==============================] - 3s 486us/step - loss: 0.6813 - accuracy: 0.7140 - val_loss: 1.3698 - val_accuracy: 0.4445\n","Epoch 6/10\n","7098/7098 [==============================] - 3s 492us/step - loss: 0.6107 - accuracy: 0.7330 - val_loss: 1.4346 - val_accuracy: 0.4493\n","Epoch 7/10\n","7098/7098 [==============================] - 3s 492us/step - loss: 0.5659 - accuracy: 0.7464 - val_loss: 1.5133 - val_accuracy: 0.4452\n","Epoch 8/10\n","7098/7098 [==============================] - 3s 486us/step - loss: 0.5446 - accuracy: 0.7474 - val_loss: 1.5803 - val_accuracy: 0.4486\n","Epoch 9/10\n","7098/7098 [==============================] - 3s 490us/step - loss: 0.5166 - accuracy: 0.7597 - val_loss: 1.6414 - val_accuracy: 0.4541\n","Epoch 10/10\n","7098/7098 [==============================] - 3s 484us/step - loss: 0.4941 - accuracy: 0.7633 - val_loss: 1.7059 - val_accuracy: 0.4479\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C1Ip9RYKMoOt","colab_type":"code","outputId":"8548b462-73c9-49a4-8c7c-65dcbd80139f","executionInfo":{"status":"ok","timestamp":1591348290801,"user_tz":-600,"elapsed":675262,"user":{"displayName":"TheYash Mash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUD7zARaUM6X7pbTn0JjfGKoCL5JJ3hkXCT1S-reY=s64","userId":"07575215316790967445"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Accuracy on the validation set\n","\n","loss, accuracy = model.evaluate(X_train_idf, y_train, verbose=False)\n","print(\"Deep Learning Model Training Accuracy: {:.4f}\".format(accuracy))\n","loss, accuracy = model.evaluate(X_val_idf, y_val, verbose=False)\n","print(\"Deep Learning Model Testing Accuracy:  {:.4f}\".format(accuracy))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Deep Learning Model Training Accuracy: 0.9649\n","Deep Learning Model Testing Accuracy:  0.4479\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-Tp8Bq4EOFol","colab_type":"code","colab":{}},"source":["#Predicting on the test set\n","\n","y_pred_deep = model.predict_classes(x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xVffYS3SSwE7","colab_type":"code","colab":{}},"source":["#Saving file as CSV\n","\n","import numpy as np\n","import pandas as pd\n","deepmodel = pd.DataFrame(y_pred_deep, columns=['Prediction'])\n","deepmodel.to_csv('/content/drive/My Drive/ML Project/tweet-emotion-detection/deepmodel.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qrzBIftscepA","colab_type":"text"},"source":["# ***7) A Description of the Selected Deep Learning Model***\n","\n","For the final model, we have used 2 dense layers and 2 dropout layers, as this gave me the best accuracy I could achieve (average of 44%) on the validation set, 54.65% on the public test set and 64.059% on the private test set. The hyperparameters were chosen by altering the epoch and batch size to get the best accuracy. Since, we have a big dataset, we set the epochs=10 and batch_size=10. Relu activation function is used since it does not activate all the neurons at the same time and softmax layer is used for multi-class classification. We have used the loss function as categorical crossentropy for single label categorization. The Adam optimizer is used as it is a stochastic gradient descent method based on adaptive estimation of first-order and second-order moments. \n","\n","In addition to the final model, I also tried a ANN with Global average pooling layer. This performed almost as well as the final model (accuracy 53% on public test set). This gap in performance may have been because average pooling assumes a single mode with a single centroid, while our distribution has more than one mode as well as outliers which leads to the average pooling not being accurate."]},{"cell_type":"markdown","metadata":{"id":"CB3OhAprceli","colab_type":"text"},"source":["# ***8) Discussion Between the Performances of the Two Models***\n","\n","Comparing my final conventional ML and deep learning models, the deep learning one performed better by 2.5% on the public test set.  The deep learning model ranked #36 out of 57 submissions on the public test set, with the top-performing system having 78.86% accuracy, and the majority of the accuracies lied between 53% to 59% for the public test set.\n","\n","On the private test set, my best model had an accuracy of 64.059% which ranked #29 out of 49 submissions, with the top-performing system having 100% accuracy, and a majority class baseline having 64% accuracy.\n","\n","******\n","***Validation Set vs Public Test Set***\n","\n","The performance on validation set versus public test set for the best Conventional ML Model and Deep Learning Model resulted in a better accuracy for the public test set in both the cases. This might be a result of overfitting on the validation data for both the cases. Also, for Deep Model, this might be due to usage of Neural Networks and usage of dropout layer which is a regularization technique. While the Dropout layer, during training, removes some random collection of these classifiers. Thus, the training accuracy suffers. While, during testing, it shuts off and lets all of the ‘weak classifiers’ in the neural network to be utilized. Thus, testing accuracy improves. It also indicates that our dataset might be slightly small.\n","\n","\n","******\n","***Public Test Set vs Private Test Set***\n","\n","While applying the deep model on public set gave an accuracy of 54.65%, it gave an accuracy of 64% on the private set. This shows that my deep model worked better on the private set and the difference between scores for the public set and the private set can be considered as a result of overfitting on the public set compared to the private set. This can be improved by increasing the amount of training data and using normalization techniques. Also, the difference in accuracies can be related to the bias of the predictor when applied to the training data versus the testing data. \n","\n","******\n","\n","I believe that in this competition, the models having very high accuracies when trained on the public test set did not perform that well on the private test set because there was too much overfitting done by the competitors on the validation set and the public test set to make the data fit well particularly to the public test set. Due to this, it lead to a lesser accuracy on the unseen private test set which was different from the public test set. This can be resolved by adding more training data. Thus, it is necessary to have a neutral bias-variance tradeoff where there is a balance between the bias and the variance to have a more generalized model."]}]}
